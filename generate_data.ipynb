{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "   \n",
    "\n",
    "def parse_arguments_generate_dataset():\n",
    "    ap = argparse.ArgumentParser(description='Using of media pipe in PSL')\n",
    "    \n",
    "    ap.add_argument('--inputPath', type=str, default=\"C:/Users/BRENDA\\Documents/SOTA/Experimentation/Data_cLSP_version2/Data/Videos/Segmented_gestures/\",\n",
    "                    help='relative path of images input.')\n",
    "\n",
    "    ap.add_argument('-wlf', '--withLineFeature', default=False, action='store_true',\n",
    "                    help=\"use line features\")\n",
    "\n",
    "    ap.add_argument('-lhl', '--leftHandLandmarks', default=True, action='store_true',\n",
    "                    help='Get left hand landmarks')\n",
    "\n",
    "    ap.add_argument('-rhl', '--rightHandLandmarks', default=True, action='store_true',\n",
    "                    help='Get right hand landmarks')\n",
    "\n",
    "    ap.add_argument('-fl', '--faceLandmarks', default=False, action='store_true',\n",
    "                    help='Get face landmarks')\n",
    "\n",
    "    ap.add_argument('-mf', '--minframes', type=int, default=10,\n",
    "                    help='Number of frames of each video')\n",
    "\n",
    "    ap.add_argument('-mi', '--mininstances', type=int, default=10,\n",
    "                    help='Number of instances of each class')\n",
    "\n",
    "    ap.add_argument('-aej', '--addExtraJoint', default=False, action='store_true',\n",
    "                    help='Add the joint number 33 (middle point of 12 and 11)')\n",
    "\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X = []\n",
    "list_Y = []\n",
    "list_pos= []\n",
    "list_frames = []\n",
    "list_videoname = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('C:/Users/BRENDA/Documents/SOTA/KNN/PSL-GAN-ad521b837aa1cabd3bbc6e72459104d0ca7cb72a/utils'))\n",
    "\n",
    "# Standard library imports\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Third party imports\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing\n",
    "import h5py\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Local imports\n",
    "from utils.parse_arguments import parse_arguments_generate_dataset\n",
    "\n",
    "\n",
    "#all the videos were resized to this\n",
    "WIDTH = HEIGHT = 220\n",
    "\n",
    "#list of landmarks to get\n",
    "# see ->  https://google.github.io/mediapipe/solutions/pose.html\n",
    "LIST_LANDMARKS = [0, 1, 2, 3, 4, 5, 6, 7,\n",
    "                 8, 9, 10, 11, 12, 13, 14,\n",
    "                 15,16,17,18,19,20,21,22 ,\n",
    "\n",
    "                 23,24,25,26,27,28,29,30,\n",
    "                31,32,33,34,35,36,37,38,39,40,41,\n",
    "                42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63\n",
    "                \n",
    "                 ]  #23   + 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_COLUMNS = [\"videoname\", \"axis\", \"n_frame\", \"n_landmark\", \"coordinate\"]\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, \n",
    "                input_path, \n",
    "                with_lf, \n",
    "                lefthand_lm, \n",
    "                righthand_lm, \n",
    "                face_lm):\n",
    "\n",
    "        self.input_path = input_path\n",
    "        self.lefthand_lm = lefthand_lm\n",
    "        self.righthand_lm = righthand_lm\n",
    "        self.face_lm = face_lm\n",
    "\n",
    "        self.mp_holistic, self.holistic, self.mp_drawing, self.drawing_spec = self.get_solution_mediapipe(with_lf)\n",
    "\n",
    "        self.folder_list = self.get_folder_list()\n",
    "\n",
    "        self.list_X = []\n",
    "        self.list_Y = []\n",
    "        self.list_pos= []\n",
    "        self.list_frames = []\n",
    "        self.list_videoname = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solution_mediapipe(self, with_lf):\n",
    "        print(\"Holistic Model\")\n",
    "        mp_holistic = mp.solutions.holistic\n",
    "\n",
    "        if with_lf:\n",
    "            print(\"   + with Line Feature\")\n",
    "            holistic = mp_holistic.Holistic(upper_body_only=True,\n",
    "                                                min_detection_confidence=0.5,\n",
    "                                                min_tracking_confidence=0.5)\n",
    "        else:\n",
    "            holistic = mp_holistic.Holistic(min_detection_confidence=0.5,\n",
    "                                                min_tracking_confidence=0.5)\n",
    "\n",
    "        # Drawing\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "        return mp_holistic, holistic, mp_drawing, drawing_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_list(self):\n",
    "        # Folder list of videos's frames\n",
    "        if os.path.isdir(self.input_path):\n",
    "            folder_list = [file for file in os.listdir(self.input_path)\n",
    "                                if os.path.isdir(self.input_path+file)]\n",
    "            print(\"Is Directory\")\n",
    "        else:\n",
    "            folder_list = [args.inputPath]\n",
    "        print(folder_list)\n",
    "        return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(self, min_frames=10, min_instances=10, use_extra_joint=False):\n",
    "    #def create_dataset(self, min_frames=15, use_extra_joint=False):\n",
    "        for video_folder_name in self.folder_list:\n",
    "            video_folder_path = self.input_path + video_folder_name\n",
    "            video_folder_list = [file for file in os.listdir(video_folder_path)]\n",
    "\n",
    "            for video_file in video_folder_list:\n",
    "                self.process_video(video_file, video_folder_path)\n",
    "\n",
    "        self.holistic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "                \"videoname\": list_videoname,\n",
    "                \"n_frame\": list_frames,\n",
    "                \"n_landmark\": list_pos,\n",
    "                \"x\": list_X,\n",
    "                \"y\": list_Y,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateDataset:\n",
    "    def __init__(self, \n",
    "                input_path, \n",
    "                with_lf, \n",
    "                lefthand_lm, \n",
    "                righthand_lm, \n",
    "                face_lm):\n",
    "\n",
    "        self.input_path = input_path\n",
    "        self.lefthand_lm = lefthand_lm\n",
    "        self.righthand_lm = righthand_lm\n",
    "        self.face_lm = face_lm\n",
    "\n",
    "        self.mp_holistic, self.holistic, self.mp_drawing, self.drawing_spec = self.get_solution_mediapipe(with_lf)\n",
    "\n",
    "        self.folder_list = self.get_folder_list()\n",
    "\n",
    "        self.list_X = []\n",
    "        self.list_Y = []\n",
    "        self.list_pos= []\n",
    "        self.list_frames = []\n",
    "        self.list_videoname = []\n",
    "\n",
    "\n",
    "    def get_solution_mediapipe(self, with_lf):\n",
    "        print(\"Holistic Model\")\n",
    "        mp_holistic = mp.solutions.holistic\n",
    "\n",
    "        if with_lf:\n",
    "            print(\"   + with Line Feature\")\n",
    "            holistic = mp_holistic.Holistic(upper_body_only=True,\n",
    "                                                min_detection_confidence=0.5,\n",
    "                                                min_tracking_confidence=0.5)\n",
    "        else:\n",
    "            holistic = mp_holistic.Holistic(min_detection_confidence=0.5,\n",
    "                                                min_tracking_confidence=0.5)\n",
    "\n",
    "        # Drawing\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "        return mp_holistic, holistic, mp_drawing, drawing_spec\n",
    "\n",
    "\n",
    "    def get_folder_list(self):\n",
    "        # Folder list of videos's frames\n",
    "        if os.path.isdir(self.input_path):\n",
    "            folder_list = [file for file in os.listdir(self.input_path)\n",
    "                                if os.path.isdir(self.input_path+file)]\n",
    "            print(\"Is Directory\")\n",
    "        else:\n",
    "            folder_list = [args.inputPath]\n",
    "        print(folder_list)\n",
    "        return folder_list\n",
    "\n",
    "\n",
    "    def create_dataset(self, min_frames=10, min_instances=10, use_extra_joint=False):\n",
    "    #def create_dataset(self, min_frames=15, use_extra_joint=False):\n",
    "        for video_folder_name in self.folder_list:\n",
    "            video_folder_path = self.input_path + video_folder_name\n",
    "            video_folder_list = [file for file in os.listdir(video_folder_path)]\n",
    "\n",
    "            for video_file in video_folder_list:\n",
    "                self.process_video(video_file, video_folder_path)\n",
    "\n",
    "        self.holistic.close()\n",
    "\n",
    "        data = {\n",
    "                \"videoname\": self.list_videoname,\n",
    "                \"n_frame\": self.list_frames,\n",
    "                \"n_landmark\": self.list_pos,\n",
    "                \"x\": self.list_X,\n",
    "                \"y\": self.list_Y,\n",
    "            }\n",
    "\n",
    "        df_or = self.filter_data(data, min_frames=min_frames, min_instances=min_instances)\n",
    "        #df_or = self.filter_data(data, min_frames=min_frames)\n",
    "        #checking\n",
    "        assert df_or.groupby([\"videoname\", \"n_frame\"]).n_landmark.nunique().std()==0 , \"Frames dont have the same number of landmarks\"\n",
    "        assert df_or.groupby(\"videoname\").agg({\"n_frame\": \"nunique\"}).n_frame.nunique()==1 and df_or.groupby(\"videoname\").agg({\"n_frame\": \"nunique\"}).n_frame.unique()[0]==min_frames, f\"Videos were not subsampled to {min_frames} frames\"\n",
    "        #esto se comentó para quitarle el min instancias pero luego se repuso para obtener con min_instances\n",
    "        assert df_or.groupby(\"class\").agg({\"videoname\": \"nunique\"}).videoname.nunique()==1 and df_or.groupby(\"class\").agg({\"videoname\": \"nunique\"}).videoname.unique()[0]==min_instances, f\"Classes dont have the same number of instances ({min_instances})\"\n",
    "\n",
    "        # classes\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(df_or[\"class\"])\n",
    "        classes_array = le.transform(df_or.groupby('videoname')[\"class\"].first().values)\n",
    "        name_classes_array = df_or.groupby('videoname')[\"class\"].first().values\n",
    "        name_classes_array = [unidecode(x) for x in name_classes_array]\n",
    "\n",
    "        assert len(classes_array) == len(name_classes_array), \"There is a problem with label encoder\"\n",
    "\n",
    "        #reshaping\n",
    "        df_or = df_or.set_index([\"videoname\", \"n_frame\", \"n_landmark\"])[[\"x\", \"y\"]].stack().reset_index()\n",
    "        df_or.rename(columns={\"level_3\": \"axis\", 0: \"coordinate\"}, inplace=True)\n",
    "\n",
    "        list_dfs = [df_or[FINAL_COLUMNS]]\n",
    "        if use_extra_joint:\n",
    "            LIST_LANDMARKS.append(33)\n",
    "            df_new_point = df_or.loc[df_or.n_landmark.isin([11, 12])].groupby([\"videoname\", \"axis\", \"n_frame\"]).agg({\"coordinate\": \"mean\"}).reset_index()\n",
    "            df_new_point[\"n_landmark\"] = 33\n",
    "            list_dfs = list_dfs + [df_new_point[FINAL_COLUMNS]]\n",
    "\n",
    "        df_or = pd.concat(list_dfs).sort_values(by=FINAL_COLUMNS[:-1], ascending=True)\n",
    "\n",
    "        assert len(df_or) % (2 * min_frames * len(LIST_LANDMARKS)) == 0, \"This shape is not correct\"\n",
    "\n",
    "        data_array = df_or['coordinate'].values.reshape((-1, 2, min_frames, len(LIST_LANDMARKS)))\n",
    "        df_or.to_csv(\"data_10_frames_10_instances_with_fingers.csv\", header = True, index = False)\n",
    "\n",
    "        \n",
    "        print(\"Saving h5 files\")\n",
    "        h5_file = h5py.File(f\"data_{min_frames}_{min_instances}_{len(LIST_LANDMARKS)}.h5\", 'w')\n",
    "        #esto se comenta cuando se quita min_instances h5_file = h5py.File(f\"data_{min_frames}_{len(LIST_LANDMARKS)}.h5\", 'w')\n",
    "\n",
    "        h5_file[\"data\"] = data_array\n",
    "        h5_file[\"labels\"] = classes_array\n",
    "        h5_file[\"name_labels\"] = name_classes_array\n",
    "\n",
    "        h5_file.close()\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "    def process_video(self, video_file, video_folder_path):\n",
    "        print(\"processing \" + video_file.split('.')[0])\n",
    "        video_seg_folder_name = video_folder_path+'/'+video_file.split('.')[0]\n",
    "\n",
    "        # Create a VideoCapture object\n",
    "        cap = cv2.VideoCapture(video_folder_path+'/'+video_file)\n",
    "\n",
    "        # Check if camera opened successfully\n",
    "        if (cap.isOpened() is False):\n",
    "            print(\"Unable to read camera feed\", video_seg_folder_name)\n",
    "\n",
    "        idx = 0\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        while ret is True:\n",
    "            self.process_frame(frame, video_file, idx)\n",
    "            ret, frame = cap.read()\n",
    "            idx += 1\n",
    "\n",
    "    \n",
    "    def process_frame(self, frame, video_file, idx):\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        imageBGR = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw annotations on the image\n",
    "        annotated_image = frame.copy()\n",
    "        annotated_image.flags.writeable = True\n",
    "\n",
    "        holisResults = self.holistic.process(imageBGR)\n",
    "\n",
    "        # POSE\n",
    "        for posi, data_point in enumerate(holisResults.pose_landmarks.landmark):\n",
    "            self.list_videoname.append(video_file[:-4])\n",
    "            self.list_frames.append(idx)\n",
    "            self.list_X.append(data_point.x)\n",
    "            self.list_Y.append(data_point.y)\n",
    "            self.list_pos.append(posi)\n",
    "\n",
    "        # Left hand\n",
    "        count_lefthand = 0\n",
    "        if self.lefthand_lm:\n",
    "            if(holisResults.left_hand_landmarks):\n",
    "                for posi, data_point in enumerate(holisResults.left_hand_landmarks.landmark):\n",
    "                    self.list_videoname.append(video_file[:-4])\n",
    "                    self.list_frames.append(idx)\n",
    "                    self.list_X.append(data_point.x)\n",
    "                    self.list_Y.append(data_point.y)\n",
    "                    self.list_pos.append(posi)\n",
    "            else:\n",
    "                for _ in range(0, 21): # 21 is the number of points taken in hands model\n",
    "                    self.list_videoname.append(video_file[:-4])\n",
    "                    self.list_frames.append(idx)\n",
    "\n",
    "                    self.list_X.append(1.0)\n",
    "                    self.list_Y.append(1.0)\n",
    "\n",
    "                    self.list_pos.append(_)\n",
    "                        \n",
    "        # Right hand\n",
    "        count_righthand = 0\n",
    "        if self.righthand_lm:\n",
    "            if(holisResults.right_hand_landmarks):\n",
    "                for posi, data_point in enumerate(holisResults.right_hand_landmarks.landmark):\n",
    "                    self.list_videoname.append(video_file[:-4])\n",
    "                    self.list_frames.append(idx)\n",
    "                    self.list_X.append(data_point.x)\n",
    "                    self.list_Y.append(data_point.y)\n",
    "                    self.list_pos.append(posi)\n",
    "            else:\n",
    "                for _ in range(0, 21):\n",
    "                    self.list_videoname.append(video_file[:-4])\n",
    "                    self.list_frames.append(idx)\n",
    "\n",
    "                    self.list_X.append(1.0)\n",
    "                    self.list_Y.append(1.0)\n",
    "\n",
    "                    self.list_pos.append(_)\n",
    "                        \n",
    "\n",
    "        # Face mesh\n",
    "        if self.face_lm:\n",
    "            if(holisResults.face_landmarks):\n",
    "                for posi, data_point in enumerate(holisResults.face_landmarks.landmark):\n",
    "                    self.list_videoname.append(video_file[:-4])\n",
    "                    self.list_frames.append(idx)\n",
    "                    self.list_X.append(data_point.x)\n",
    "                    self.list_Y.append(data_point.y)\n",
    "                    self.list_pos.append(posi)\n",
    "            else:\n",
    "                print(\"Mediapipe couldnt get face landmarks\")\n",
    "\n",
    "    #se borró el min instances\n",
    "    #se puso de nuevo el min_instances\n",
    "    def filter_data(self, data, min_frames=10,  min_instances=10):\n",
    "        df = pd.DataFrame(data)  \n",
    "\n",
    "        df['class'] = df['videoname'].apply(lambda x: x.split('_')[0])\n",
    "        df['number'] = df['videoname'].apply(lambda x: x.split('_')[1])\n",
    "        df['out_range?'] = (df['x']*WIDTH > WIDTH) | (df['y']*HEIGHT > HEIGHT)\n",
    "\n",
    "        df_or = df.loc[df['out_range?']==False, :].reset_index(drop=True)\n",
    "\n",
    "        df_flag_lm = df_or.groupby(['videoname', 'n_frame', 'n_landmark']).x.count().unstack()\n",
    "        df_flag_lm[\"have_landmarks?\"] = df_flag_lm[LIST_LANDMARKS].sum(1) == len(LIST_LANDMARKS)\n",
    "\n",
    "        df_check1 = df_flag_lm[df_flag_lm[\"have_landmarks?\"]==True].reset_index().groupby(\"videoname\").agg({\"n_frame\": [\"sum\", \"max\"]})\n",
    "        df_check1.columns = [ x[0] + \"_\" + x[1] for x in df_check1.columns]\n",
    "        df_check1[\"all_frames?\"] = df_check1[\"n_frame_sum\"] == df_check1[\"n_frame_max\"]*(df_check1[\"n_frame_max\"]+1)/2\n",
    "\n",
    "        df_or = df_or.join(df_flag_lm[\"have_landmarks?\"], on=[\"videoname\", \"n_frame\"])\n",
    "        df_or = df_or.join(df_check1[\"all_frames?\"], on=\"videoname\")\n",
    "\n",
    "        # applying filters - landmarks\n",
    "        print()\n",
    "        print(\"Original\")\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        print()\n",
    "        print(\"Filter: list of landmarks\")\n",
    "        df_or = df_or.loc[df_or.n_landmark.isin(LIST_LANDMARKS)]\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        print()\n",
    "        print(\"Filter: frames that have all landmarks\")\n",
    "        df_or = df_or.loc[df_or[\"have_landmarks?\"]]\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        print()\n",
    "        print(\"Filter: videos which all frames have those landmarks\")\n",
    "        df_or = df_or.loc[df_or[\"all_frames?\"]]\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        df_or_nframes = df_or.groupby(\"videoname\").agg({\"n_frame\": \"nunique\"}).rename(columns={\"n_frame\": \"n_frames\"})\n",
    "        df_or = df_or.join(df_or_nframes, on=\"videoname\")\n",
    "\n",
    "        print()\n",
    "        print(\"Filter: min number of frames\")\n",
    "        df_or = df_or.loc[df_or.n_frames>=min_frames]\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        df_or_class = df_or.groupby(\"class\").agg({\"videoname\": \"nunique\"}).rename(columns={\"videoname\": \"n_instances\"})\n",
    "        df_or = df_or.join(df_or_class, on=\"class\")\n",
    "\n",
    "        df_or = df_or.loc[df_or[\"class\"]!=\"NNN\"].reset_index(drop=True)\n",
    "\n",
    "        ####esto se comenta cuando se quiere quitar min instances\n",
    "        \n",
    "        print()\n",
    "        print(f\"Filter: classes of at least {min_instances} instances\")\n",
    "        df_or = df_or.loc[df_or.n_instances>=min_instances].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "\n",
    "        ### UNDERSAMPLING TO HAVE THE SAME NUMBER OF INSTANCES OF EACH CLASS\n",
    "        gg = df_or.groupby([\"class\", \"videoname\"]).n_instances.unique().reset_index()\n",
    "        gg  = gg.groupby('class').apply(lambda x: x.sample(min_instances))\n",
    "        gg[\"instance_to_use?\"] = True\n",
    "        df_or = df_or.join(gg.reset_index(drop=True).set_index([\"class\", \"videoname\"])[\"instance_to_use?\"], on=[\"class\", \"videoname\"])\n",
    "\n",
    "        print()\n",
    "        print(f\"Filter: subsampling {min_instances} instances frames for each video\")\n",
    "        df_or = df_or.loc[df_or[\"instance_to_use?\"]==True].reset_index(drop=True)\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "       \n",
    "        \n",
    "\n",
    "        ####acá termina el comentario de arriba\n",
    "\n",
    "\n",
    "        #COMMENT IT\n",
    "\n",
    "\n",
    "        \n",
    "        # subsampling min_frames\n",
    "        xd = df_or.groupby([\"videoname\", \"n_frame\"]).agg({\"n_frames\": \"first\"})\n",
    "        xd['rate'] = xd['n_frames'].apply(lambda x: math.ceil(x/min_frames))\n",
    "        xd = xd.reset_index()\n",
    "        xd['valid_frame?'] = xd['n_frame'] % xd['rate'] == 0\n",
    "        xd['missing_frames'] = min_frames - xd['n_frames'].apply(lambda x: math.ceil(x/math.ceil(x/min_frames))) \n",
    "        \n",
    "        xd_valid = xd.loc[(~xd['valid_frame?']) &\n",
    "                            (xd.missing_frames>0)]\n",
    "        xd_valid['row_number_video'] = xd_valid.groupby(['videoname'])['n_frame'].cumcount() + 1 \n",
    "\n",
    "        xd_valid['upper_value'] = xd_valid.apply(lambda x: math.floor((x['n_frames'] - (min_frames - x['missing_frames']))/2) \n",
    "                                                   + x['missing_frames'] - math.floor(x['missing_frames']/2), axis=1)\n",
    "        xd_valid['lower_value'] = xd_valid.apply(lambda x: math.floor((x['n_frames'] - (min_frames - x['missing_frames']))/2) \n",
    "                                                        - math.floor(x['missing_frames']/2), axis=1)\n",
    "\n",
    "        xd_valid.loc[((xd_valid['lower_value']<xd_valid['upper_value']) & \n",
    "                    (xd_valid['row_number_video']>xd_valid['lower_value']) & \n",
    "                    (xd_valid['row_number_video']<=xd_valid['upper_value']))|\n",
    "                    ((xd_valid['lower_value']==xd_valid['upper_value']) &\n",
    "                    (xd_valid['row_number_video']==xd_valid['upper_value'])), 'valid_frame?'] = True\n",
    "\n",
    "        xd = xd.merge(xd_valid[['videoname', 'n_frame', 'valid_frame?']].rename(columns={'valid_frame?': 'valid_frame2?'}),\n",
    "                        how='left', on=['videoname', 'n_frame'])\n",
    "        xd.loc[(~xd['valid_frame?']) & \n",
    "                (xd['valid_frame2?']), 'valid_frame?'] = xd['valid_frame2?']\n",
    "\n",
    "        df_or = df_or.join(xd.set_index(['videoname', 'n_frame'])[\"valid_frame?\"], on=['videoname', 'n_frame'])\n",
    "\n",
    "        print()\n",
    "        print(f\"Filter: {min_frames} frames for each video\")\n",
    "        df_or = df_or.loc[df_or[\"valid_frame?\"]].reset_index(drop=True)\n",
    "        print(f\"Shape {df_or.shape} - N classes\", df_or[\"class\"].nunique(), \n",
    "            \" - Number of videos\", df_or[\"videoname\"].nunique())\n",
    "\n",
    "        return df_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--inputPath INPUTPATH] [-wlf] [-lhl] [-rhl]\n",
      "                             [-fl] [-mf MINFRAMES] [-mi MININSTANCES] [-aej]\n",
      "ipykernel_launcher.py: error: argument -fl/--faceLandmarks: ignored explicit argument 'C:\\\\Users\\\\BRENDA\\\\AppData\\\\Local\\\\Temp\\\\tmp-19004MROiG9NJ10s0.json'\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 1787, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 1993, in _parse_known_args\n",
      "    start_index = consume_optional(start_index)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 1915, in consume_optional\n",
      "    raise ArgumentError(action, msg % explicit_arg)\n",
      "argparse.ArgumentError: argument -fl/--faceLandmarks: ignored explicit argument 'C:\\\\Users\\\\BRENDA\\\\AppData\\\\Local\\\\Temp\\\\tmp-19004MROiG9NJ10s0.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\BRENDA\\AppData\\Local\\Temp/ipykernel_6584/2934037888.py\", line 2, in <module>\n",
      "    args = parse_arguments_generate_dataset()\n",
      "  File \"c:\\Users\\BRENDA\\Documents\\SOTA\\KNN\\PSL-GAN-ad521b837aa1cabd3bbc6e72459104d0ca7cb72a\\utils\\parse_arguments.py\", line 36, in parse_arguments_generate_dataset\n",
      "    args = ap.parse_args()\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 1755, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 1794, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 2508, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\argparse.py\", line 2495, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\BRENDA\\anaconda3\\envs\\pose\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1786\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m             \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1788\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   1992\u001b[0m             \u001b[1;31m# consume the next optional and any arguments for it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m             \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsume_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36mconsume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignored explicit argument %r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mexplicit_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument -fl/--faceLandmarks: ignored explicit argument 'C:\\\\Users\\\\BRENDA\\\\AppData\\\\Local\\\\Temp\\\\tmp-19004MROiG9NJ10s0.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6584/2934037888.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_arguments_generate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\BRENDA\\Documents\\SOTA\\KNN\\PSL-GAN-ad521b837aa1cabd3bbc6e72459104d0ca7cb72a\\utils\\parse_arguments.py\u001b[0m in \u001b[0;36mparse_arguments_generate_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1755\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1793\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2495\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2069\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m   2070\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[1;32m-> 2071\u001b[1;33m                                                                      value))\n\u001b[0m\u001b[0;32m   2072\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[0;32m    632\u001b[0m                 \u001b[1;33m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m                 + out_list)\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1368\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1268\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             )\n\u001b[0;32m   1270\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1125\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pose\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_arguments_generate_dataset()\n",
    "\n",
    "    input_path = args.inputPath\n",
    "    with_lf = args.withLineFeature\n",
    "    lefthand_lm = args.leftHandLandmarks\n",
    "    righthand_lm = args.rightHandLandmarks\n",
    "    face_lm = args.faceLandmarks\n",
    "    min_frames = args.minframes\n",
    "    min_instances = args.mininstances\n",
    "    use_extra_joint = False\n",
    "\n",
    "    set_seed(12345)\n",
    "\n",
    "    gds = GenerateDataset(input_path, with_lf, lefthand_lm, righthand_lm, face_lm)\n",
    "    gds.create_dataset(min_frames, min_instances, use_extra_joint)\n",
    "    #esto se comenta cuando se quiere eliminar min instances gds.create_dataset(min_frames, use_extra_joint)\n",
    "    ## 23 joins \n",
    "\n",
    "\n",
    "    #feature array -> 23 * #clases * 10 * 2 = resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc0cd85f639b4e26c1c0f19227d338aab18cc5094f74e0b45912f71445b6615"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pose')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
